{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import Dataset, Reader, accuracy\n",
    "from surprise import SVD, KNNBasic, KNNWithMeans, KNNWithZScore, KNNBaseline \n",
    "from surprise.model_selection import train_test_split, cross_validate\n",
    "from surprise.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'surprise.trainset.Trainset'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Load the MovieLens dataset - https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
    "movies = pd.read_csv('./data/movies.csv')\n",
    "ratings = pd.read_csv('./data/ratings.csv')\n",
    "# Data encoding using Surprise library\n",
    "reader = Reader(rating_scale=(0.5, 5.0))  # Define the rating scale using Reader class from Surprise\n",
    "\n",
    "# Convert the DataFrame to a Surprise dataset\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "# Split dataset using train_test_split from Surprise\n",
    "trainset, testset = train_test_split(data, test_size=0.2) # 80% training and 20% testing\n",
    "print(type(trainset))\n",
    "print(type(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from surprise import Dataset, SVD\n",
    "from surprise.model_selection import KFold\n",
    "\n",
    "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
    "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(\n",
    "            ((true_r >= threshold) and (est >= threshold))\n",
    "            for (est, true_r) in user_ratings[:k]\n",
    "        )\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        # When n_rec_k is 0, Precision is undefined. We here set it to 0.\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        # When n_rel is 0, Recall is undefined. We here set it to 0.\n",
    "\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "\n",
    "    return precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6021346469622345\n",
      "0.24324516025267232\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#data = Dataset.load_builtin(\"ml-100k\")\n",
    "#kf = KFold(n_splits=2)\n",
    "algo = SVD()\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "precisions, recalls = precision_recall_at_k(predictions, k=5, threshold=4)\n",
    "\n",
    "# Precision and recall can then be averaged over all users\n",
    "print(sum(prec for prec in precisions.values()) / len(precisions))\n",
    "print(sum(rec for rec in recalls.values()) / len(recalls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "   uid    iid  r_ui       est                    details\n",
      "0  317  44555   4.0  4.020991  {'was_impossible': False}\n",
      "1  513    150   4.5  4.174174  {'was_impossible': False}\n",
      "2  402    719   3.0  3.501272  {'was_impossible': False}\n",
      "3  599   1917   3.0  2.112975  {'was_impossible': False}\n",
      "4  307   2515   1.5  2.643389  {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "print(type(predictions))\n",
    "print(pd.DataFrame(predictions).head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction(uid=317, iid=44555, r_ui=4.0, est=4.0209912899719535, details={'was_impossible': False}), Prediction(uid=513, iid=150, r_ui=4.5, est=4.174174044680569, details={'was_impossible': False}), Prediction(uid=402, iid=719, r_ui=3.0, est=3.501272124672278, details={'was_impossible': False}), Prediction(uid=599, iid=1917, r_ui=3.0, est=2.1129750181624902, details={'was_impossible': False}), Prediction(uid=307, iid=2515, r_ui=1.5, est=2.6433891401336385, details={'was_impossible': False})]\n",
      "Showing first 10 predictions:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "User ID  Movie ID Movie Title                              Actual   Predicted Error   \n",
      "----------------------------------------------------------------------------------------------------\n",
      "317      44555    Lives of Others, The (Das leben der...   4.00     4.02     -0.02   \n",
      "513      150      Apollo 13 (1995)                         4.50     4.17     0.33    \n",
      "402      719      Multiplicity (1996)                      3.00     3.50     -0.50   \n",
      "599      1917     Armageddon (1998)                        3.00     2.11     0.89    \n",
      "307      2515     Children of the Corn II: The Final ...   1.50     2.64     -1.14   \n",
      "526      1732     Big Lebowski, The (1998)                 4.50     4.59     -0.09   \n",
      "44       12       Dracula: Dead and Loving It (1995)       1.00     2.82     -1.82   \n",
      "4        1916     Buffalo '66 (a.k.a. Buffalo 66) (1998)   1.00     3.76     -2.76   \n",
      "414      37739    Greatest Game Ever Played, The (2005)    3.50     3.65     -0.15   \n",
      "177      95654    Geri's Game (1997)                       3.50     3.25     0.25    \n"
     ]
    }
   ],
   "source": [
    "print(predictions[0:5])\n",
    "def head_predictions(predictions_list, n=5, include_titles=True):\n",
    "    \"\"\"\n",
    "    Display the first n predictions in a readable format, similar to df.head()\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    predictions_list : list\n",
    "        List of Surprise prediction objects\n",
    "    n : int, optional (default=5)\n",
    "        Number of predictions to show\n",
    "    include_titles : bool, optional (default=True)\n",
    "        Whether to include movie titles in the output\n",
    "    \"\"\"\n",
    "    # Ensure n is not larger than the list\n",
    "    n = min(n, len(predictions_list))\n",
    "    \n",
    "    # Print header\n",
    "    print(f\"Showing first {n} predictions:\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    if include_titles:\n",
    "        print(f\"{'User ID':<8} {'Movie ID':<8} {'Movie Title':<40} {'Actual':<8} {'Predicted':<8} {'Error':<8}\")\n",
    "    else:\n",
    "        print(f\"{'User ID':<8} {'Movie ID':<8} {'Actual':<8} {'Predicted':<8} {'Error':<8}\")\n",
    "    \n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    # Print each prediction\n",
    "    for i, pred in enumerate(predictions_list[:n]):\n",
    "        user_id = pred.uid\n",
    "        movie_id = pred.iid\n",
    "        actual = pred.r_ui\n",
    "        predicted = pred.est\n",
    "        error = actual - predicted\n",
    "        \n",
    "        if include_titles:\n",
    "            # Get movie title if available\n",
    "            title_row = movies[movies['movieId'] == movie_id]\n",
    "            title = title_row['title'].values[0] if not title_row.empty else \"Unknown\"\n",
    "            \n",
    "            # Truncate title if too long\n",
    "            if len(title) > 38:\n",
    "                title = title[:35] + \"...\"\n",
    "            \n",
    "            print(f\"{user_id:<8} {movie_id:<8} {title:<40} {actual:<8.2f} {predicted:<8.2f} {error:<8.2f}\")\n",
    "        else:\n",
    "            print(f\"{user_id:<8} {movie_id:<8} {actual:<8.2f} {predicted:<8.2f} {error:<8.2f}\")\n",
    "\n",
    "# Show the first 10 predictions with movie titles\n",
    "head_predictions(predictions, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
